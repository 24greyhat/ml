{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72949449-1bdf-442c-8666-cc0ea8a67ae0",
   "metadata": {},
   "source": [
    "# Playing with datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f79867-7748-4c29-9920-1e0bac56a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae40d9c9-056c-44ed-a923-cf432c9b0ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 61] Connection refused>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 9.91M/9.91M [00:01<00:00, 5.80MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 61] Connection refused>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 175kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 61] Connection refused>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 1.65M/1.65M [00:01<00:00, 1.56MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 61] Connection refused>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 4.54k/4.54k [00:00<00:00, 1.34MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])) # download training data and transform it into a torch tensor\n",
    "\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])) # same but for testing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47807fbf-99c3-409e-859e-8e9969664a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "# Batch_size = is the size of each batch being passed to the model at a time, a batch is a set of samples of length batch_size, each sample is made of an input feature vector and a corresponding label (target value).\n",
    "# shuffle = shuffle the data to improve generalization\n",
    "\n",
    "\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c44d7-142b-4b1e-b049-1e129dcaa82d",
   "metadata": {},
   "source": [
    "# Batches\n",
    "\n",
    "- Passing our data via batches allows for better generalization and fitting of our overall data.\n",
    "  \n",
    "- If we pass the entire dataset, as the model tries to optmize all the weights, biases and connections the model will be able to make some generalization but it won't be very effective when dealing with new novel inputs that it hasn't observed in the training set.\n",
    "  \n",
    "- Batches make it possible to train a model on terabytes of data one batch at a time and they also drastically lower the probability of overfitting.\n",
    "\n",
    "- most common batch size is between **8** and **64** regardless of the size of the memory and or data one has access to.\n",
    "\n",
    "- The bigger the batch size the faster the training and vice versa (training time & generalization tradeoff)\n",
    "\n",
    "\n",
    "\n",
    "# The datasets and Objectives\n",
    "\n",
    "\n",
    "\n",
    "## Datasets\n",
    "\n",
    "- The MNIST datasets are hand-drawn images of numbers from 0 to 9\n",
    "\n",
    "\n",
    "# Objectives\n",
    " \n",
    "- The name of the game is generalization\n",
    "\n",
    "- If you take a neural network and feed it a bunch of zeros the nn will learn to optimize for zeros and will classify everything as a zero\n",
    "\n",
    "- If you train it on ones instead of zeros it will classify everything as a one and until you get to the nines it will optimize for nines and classify everything as a 9\n",
    "\n",
    "- If you shuffle your datasets you give the nn the opportunity to learn general principles rather then just simply figuring out little tricks to minimize loss.\n",
    "\n",
    "- The neural network will take the quickest route to minimizing loss even at the expense of generalization so shuffling the data is cruicial.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "317f16ab-dae9-422b-937a-dfbbd1938407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([1, 9, 3, 8, 8, 5, 1, 8, 1, 9])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e7146-ab2a-4a17-a0f1-9719d17b5004",
   "metadata": {},
   "source": [
    "- data is a tensor object containing\n",
    "  1) a tensor of tensors holding the images\n",
    "  2) a tensor of tensors holding the labels (the actual numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d3c19e7-51e1-4740-99a8-2f66e2d81da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0] \n",
    "\n",
    "# x is the zeroth image \n",
    "# y is the zeroth label\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0298b4e-fad6-411a-a48d-2cdd559920c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x160f33a50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][1].view(28, 28)) # imshow will display the image\n",
    "# .view method returns a new tensor with the same data as trhe self tensor but of a different shape, specified in the args.\n",
    "# the reason we reshape it because the original tensor has a shape of (1, 28, 28) which can't be passed to imgshow\n",
    "\n",
    "\n",
    "#plt.show(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c64fe24-4a0c-495c-a218-e793cb0f4030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        total+=1\n",
    "\n",
    "print(counter_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab365770-2132-4ec4-b60b-740dbdd16ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\") # displaying the percentage of each number in our dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133ec1b-9531-4b91-9353-acec8fe6fae1",
   "metadata": {},
   "source": [
    "# Batch diversity and Model Generalization\n",
    "\n",
    "- Iterating over and printing the percentage of each sample in our batch allows us to observe the batche's diversity and equity.\n",
    "\n",
    "- all samples in a batch must be balanced and somewhat diverse.\n",
    "\n",
    "- example:\n",
    "\n",
    "    - lets say the number 3 sample contributes to around 60% of our batch's samples, the NN will learn that the quickest way to decrease loss is to predict a 3 because it contributes to 60% of the sampele's in our batch.\n",
    "      \n",
    "    - The model will get stuck because the only way to get better (e.g. more accurate) is to have a higher loss which is not feasible and the only way to decrease loss is to predict 3 all the time which is not the desired outcome.\n",
    "      \n",
    "    - Shuffling and having each sample contribute to roughly equal proportions of the batch resolves this issue and allows the model to learn and to generalize.\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    ">**Takeaway:** Iterating over and printing the percentage of each sample in a single or a few batches is important to gain insights into the data before training.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
